{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f9d5c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e01dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = sigmoid(x)\n",
    "\n",
    "plt.plot(x, y, 'g')\n",
    "plt.plot([0,0],[1.0,0.0], ':') # 가운데 점선 추가\n",
    "plt.title('Sigmoid Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eef544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y1 = sigmoid(0.5*x)\n",
    "y2 = sigmoid(x)\n",
    "y3 = sigmoid(2*x)\n",
    "\n",
    "plt.plot(x, y1, 'r', linestyle='--') # w의 값이 0.5일때\n",
    "plt.plot(x, y2, 'g') # w의 값이 1일때\n",
    "plt.plot(x, y3, 'b', linestyle='--') # w의 값이 2일때\n",
    "plt.plot([0,0],[1.0,0.0], ':') # 가운데 점선 추가\n",
    "plt.title('Sigmoid Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fb1d59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y1 = sigmoid(x+0.5)\n",
    "y2 = sigmoid(x+1)\n",
    "y3 = sigmoid(x+1.5)\n",
    "\n",
    "plt.plot(x, y1, 'r', linestyle='--') # x + 0.5\n",
    "plt.plot(x, y2, 'g') # x + 1\n",
    "plt.plot(x, y3, 'b', linestyle='--') # x + 1.5\n",
    "plt.plot([0,0],[1.0,0.0], ':') # 가운데 점선 추가\n",
    "plt.title('Sigmoid Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48c44eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 22.4086\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5613\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.7145\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.8688\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.0260\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.1907\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3786\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.6584\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5970\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.3666\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3398\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.3255\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3166\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3104\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3059\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3025\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2999\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2978\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2961\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2947\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2936\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2926\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2917\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2910\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2903\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2897\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2892\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.2887\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.2883\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2879\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2875\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2872\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2869\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2865\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2862\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2860\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2857\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2854\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2852\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.2849\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2847\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2845\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2842\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2840\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2838\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2836\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2834\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2831\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2829\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2827\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2825\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2823\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2821\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2819\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2817\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2815\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2813\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2811\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2809\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2807\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2805\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2803\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2801\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2799\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2797\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2795\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2793\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2791\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2789\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2788\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2786\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2784\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2782\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2780\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2778\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2776\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2774\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2772\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2770\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2769\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2767\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2765\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2763\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2761\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2759\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2757\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2755\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2754\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.2752\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2750\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2748\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2746\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2744\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2742\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2741\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2739\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2737\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2735\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2733\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2731\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2730\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2728\n",
      "Epoch 103/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2726\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.2724\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.2722\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2721\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2719\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2717\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2715\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2713\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2712\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2710\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2708\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2706\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2704\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2703\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2701\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2699\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2697\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2696\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2694\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2692\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2690\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2688\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2687\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2685\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2683\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2681\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2680\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2678\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2676\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2675\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2673\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2671\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2669\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2668\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2666\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2664\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2662\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2661\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2659\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2657\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2656\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2654\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2652\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2650\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2649\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2647\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2645\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2644\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2642\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2640\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2639\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2637\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2635\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2634\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2632\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2630\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2629\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2627\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2625\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2624\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2622\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2620\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2619\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2617\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2615\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2614\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2612\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2610\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2609\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2607\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2605\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.2604\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2602\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2601\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2599\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2597\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2596\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2594\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2592\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2591\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2589\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2588\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2586\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2584\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2583\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2581\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2580\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2578\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2576\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2575\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2573\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2572\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2570\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2569\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2567\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2565\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2564\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1581d8033d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "x = np.array([-50, -30, -10, 0, 5, 10, 15, 20])\n",
    "y = np.array([0, 0, 0, 0, 0, 1, 1, 1]) # 숫자 10부터 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=1, activation='sigmoid'))\n",
    "\n",
    "sgd = optimizers.SGD(learning_rate=0.01)\n",
    "model.compile(optimizer=sgd, loss='binary_crossentropy')\n",
    "model.fit(x, y, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "513f4688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1581dc3f310>,\n",
       " <matplotlib.lines.Line2D at 0x1581dc3f340>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, model.predict(x), 'b', x,y, 'k.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be538697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.2387210e-05]\n",
      " [1.4595985e-03]\n",
      " [8.7132812e-02]\n",
      " [4.3543977e-01]\n",
      " [6.8676585e-01]\n",
      " [8.6173499e-01]\n",
      " [9.4657183e-01]\n",
      " [9.8053050e-01]]\n",
      "[[0.48731673]\n",
      " [0.53946835]\n",
      " [0.59076995]\n",
      " [0.64016855]\n",
      " [0.6638657 ]]\n",
      "[[0.88480306]\n",
      " [0.9841435 ]\n",
      " [0.99801004]\n",
      " [0.99975336]\n",
      " [1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(x))\n",
    "print(model.predict([1, 2, 3, 4, 4.5]))\n",
    "print(model.predict([11, 21, 31, 41, 500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0960b84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data set\n",
    "x_data = np.array([-5, -4, -3, -2, -1, 0,1,2,3,4,5,6])\n",
    "y_data = np.array([ 0,  0, 0,   0,  0, 0,0,1,1,1,1,1])\n",
    "\n",
    "# model: linear regression input dense with dim =1\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim = 1, activation='sigmoid'))\n",
    "\n",
    "# model compile:  SGD learning_rate of 0.01 \n",
    "sgd = optimizers.SGD(learning_rate = 0.01)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd)\n",
    "\n",
    "# model fit\n",
    "history = model.fit(x_data, y_data, epochs=300, batch_size=1, shuffle=False)\n",
    "\n",
    "loss_and_metric = model.evaluate(x_data, y_data, batch_size=1)\n",
    "print ('Evaluate:\\n', loss_and_metric)\n",
    "\n",
    "# prediction\n",
    "print ('Predict:\\n', model.predict([7, -2, -3, 2, 1]))\n",
    "\n",
    "# print model summary\n",
    "print ('Model summary:\\n')\n",
    "model.summary()\n",
    "\n",
    "# 학습 정확성 값과 검증 정확성 값을 플롯팅 합니다. \n",
    "# #print(history.history)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel('Loss (binary_crossentropy)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.savefig('03_tran_result.png')\n",
    "#plt.show()\n",
    "plt.clf()\n",
    "\n",
    "plt.plot (x_data, model.predict(x_data), 'b', x_data, y_data, 'k.')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
